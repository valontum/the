{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Articles\n",
      "\n",
      "http://www.totalpolitics.com: 0\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 2 of 3784\n",
      "File not Downloaded 1 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 5 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 6 of 3784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:228: DeprecationWarning: update is deprecated. Use replace_one, update_one or update_many instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "File not Downloaded 7 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 4 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 3 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 8 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 9 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 10 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 11 of 3784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:76: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:77: DeprecationWarning: update is deprecated. Use replace_one, update_one or update_many instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "File not Downloaded 12 of 3784\n",
      "Downloaded file 13 of 3784\n",
      "duplicated\n",
      "Downloaded file 14 of 3784\n",
      "Downloaded file 15 of 3784\n",
      "Downloaded file 17 of 3784\n",
      "duplicated\n",
      "Downloaded file 16 of 3784\n",
      "duplicated\n",
      "Downloaded file 18 of 3784\n",
      "Downloaded file 19 of 3784\n",
      "Downloaded file 21 of 3784\n",
      "duplicated\n",
      "Downloaded file 20 of 3784\n",
      "duplicated\n",
      "Downloaded file 22 of 3784\n",
      "Downloaded file 23 of 3784\n",
      "Downloaded file 26 of 3784\n",
      "duplicated\n",
      "Downloaded file 24 of 3784\n",
      "duplicated\n",
      "Downloaded file 25 of 3784\n",
      "Downloaded file 27 of 3784\n",
      "duplicated\n",
      "Downloaded file 28 of 3784\n",
      "Downloaded file 30 of 3784\n",
      "duplicated\n",
      "Downloaded file 29 of 3784\n",
      "Downloaded file 32 of 3784\n",
      "duplicated\n",
      "Downloaded file 31 of 3784\n",
      "Downloaded file 33 of 3784\n",
      "Downloaded file 35 of 3784\n",
      "duplicated\n",
      "Downloaded file 36 of 3784\n",
      "duplicated\n",
      "Downloaded file 34 of 3784\n",
      "Downloaded file 39 of 3784\n",
      "Downloaded file 37 of 3784\n",
      "duplicated\n",
      "Downloaded file 40 of 3784\n",
      "Downloaded file 43 of 3784\n",
      "duplicated\n",
      "Downloaded file 44 of 3784\n",
      "duplicated\n",
      "Downloaded file 38 of 3784\n",
      "Downloaded file 45 of 3784\n",
      "duplicated\n",
      "Downloaded file 46 of 3784\n",
      "Downloaded file 41 of 3784\n",
      "duplicated\n",
      "Downloaded file 42 of 3784\n",
      "Downloaded file 48 of 3784\n",
      "Downloaded file 49 of 3784\n",
      "duplicated\n",
      "Downloaded file 47 of 3784\n",
      "duplicated\n",
      "Downloaded file 50 of 3784\n",
      "Downloaded file 51 of 3784\n",
      "Downloaded file 53 of 3784\n",
      "duplicated\n",
      "Downloaded file 54 of 3784\n",
      "duplicated\n",
      "Downloaded file 52 of 3784\n",
      "Downloaded file 55 of 3784\n",
      "duplicated\n",
      "Downloaded file 56 of 3784\n",
      "Downloaded file 57 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 61 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 62 of 3784\n",
      "duplicated\n",
      "Downloaded file 58 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 63 of 3784\n",
      "Downloaded file 60 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 64 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 65 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 66 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 68 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 67 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 69 of 3784\n",
      "duplicated\n",
      "Downloaded file 59 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 70 of 3784\n",
      "duplicated\n",
      "Downloaded file 74 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 73 of 3784\n",
      "Downloaded file 75 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 77 of 3784\n",
      "Downloaded file 76 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 78 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 79 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 80 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 81 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 72 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 71 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 82 of 3784list index out of range\n",
      "\n",
      "File not Downloaded 83 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 87 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 88 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 89 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 90 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 91 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 92 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 93 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 94 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 95 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 96 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 97 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 98 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 99 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 100 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 101 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 102 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 103 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 104 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 105 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 106 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 107 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 108 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 109 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 110 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 111 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 112 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 113 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 114 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 115 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 85 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 84 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "File not Downloaded 116 of 3784File not Downloaded 117 of 3784File not Downloaded 118 of 3784list index out of range\n",
      "\n",
      "\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known>File not Downloaded 86 of 3784<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "File not Downloaded 120 of 3784\n",
      "File not Downloaded 119 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 121 of 3784<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known>File not Downloaded 122 of 3784File not Downloaded 124 of 3784\n",
      "\n",
      "\n",
      "File not Downloaded 123 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 125 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>File not Downloaded 126 of 3784\n",
      "\n",
      "\n",
      "File not Downloaded 127 of 3784File not Downloaded 128 of 3784\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 129 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 132 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 133 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 134 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 130 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 136 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 131 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 135 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 137 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 138 of 3784\n",
      "duplicated\n",
      "Downloaded file 140 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 139 of 3784\n",
      "duplicated\n",
      "Downloaded file 141 of 3784\n",
      "duplicated\n",
      "Downloaded file 142 of 3784\n",
      "duplicated\n",
      "Downloaded file 143 of 3784\n",
      "duplicated\n",
      "Downloaded file 144 of 3784\n",
      "Downloaded file 146 of 3784\n",
      "duplicated\n",
      "Downloaded file 145 of 3784\n",
      "duplicated\n",
      "Downloaded file 147 of 3784\n",
      "Downloaded file 151 of 3784Downloaded file 149 of 3784\n",
      "\n",
      "duplicated\n",
      "Downloaded file 148 of 3784\n",
      "duplicated\n",
      "Downloaded file 150 of 3784\n",
      "Downloaded file 153 of 3784\n",
      "duplicated\n",
      "Downloaded file 152 of 3784\n",
      "Downloaded file 154 of 3784\n",
      "duplicated\n",
      "Downloaded file 155 of 3784\n",
      "Downloaded file 156 of 3784\n",
      "duplicated\n",
      "Downloaded file 157 of 3784\n",
      "Downloaded file 161 of 3784\n",
      "duplicated\n",
      "Downloaded file 160 of 3784\n",
      "duplicated\n",
      "Downloaded file 159 of 3784Downloaded file 158 of 3784\n",
      "\n",
      "Downloaded file 162 of 3784\n",
      "duplicated\n",
      "Downloaded file 163 of 3784\n",
      "Downloaded file 164 of 3784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicated\n",
      "Downloaded file 165 of 3784\n",
      "Downloaded file 166 of 3784\n",
      "duplicated\n",
      "Downloaded file 167 of 3784\n",
      "Downloaded file 168 of 3784\n",
      "duplicated\n",
      "Downloaded file 169 of 3784\n",
      "Downloaded file 171 of 3784\n",
      "Downloaded file 172 of 3784\n",
      "duplicated\n",
      "Downloaded file 170 of 3784\n",
      "duplicated\n",
      "Downloaded file 173 of 3784\n",
      "Downloaded file 175 of 3784\n",
      "Downloaded file 177 of 3784\n",
      "duplicated\n",
      "Downloaded file 174 of 3784\n",
      "duplicated\n",
      "Downloaded file 176 of 3784\n",
      "Downloaded file 178 of 3784\n",
      "Downloaded file 182 of 3784\n",
      "duplicated\n",
      "Downloaded file 179 of 3784\n",
      "Downloaded file 181 of 3784\n",
      "duplicated\n",
      "Downloaded file 183 of 3784\n",
      "Downloaded file 184 of 3784\n",
      "duplicated\n",
      "Downloaded file 185 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 188 of 3784\n",
      "duplicated\n",
      "Downloaded file 180 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 189 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 190 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 191 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 192 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 193 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 194 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 195 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 196 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 197 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 198 of 3784\n",
      "Downloaded file 186 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 201 of 3784\n",
      "duplicated\n",
      "Downloaded file 202 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 199 of 3784\n",
      "duplicated\n",
      "Downloaded file 203 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "list index out of rangeFile not Downloaded 205 of 3784\n",
      "\n",
      "File not Downloaded 200 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 207 of 3784File not Downloaded 206 of 3784\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 209 of 3784\n",
      "File not Downloaded 208 of 3784\n",
      "duplicated\n",
      "Downloaded file 187 of 3784\n",
      "duplicated\n",
      "Downloaded file 204 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 211 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 210 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 215 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "list index out of rangeFile not Downloaded 216 of 3784\n",
      "\n",
      "File not Downloaded 212 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 217 of 3784\n",
      "File not Downloaded 218 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 219 of 3784\n",
      "File not Downloaded 220 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 221 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 222 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "File not Downloaded 223 of 3784\n",
      "File not Downloaded 224 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 225 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 226 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>File not Downloaded 227 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 228 of 3784\n",
      "File not Downloaded 213 of 3784\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 229 of 3784\n",
      "\n",
      "File not Downloaded 230 of 3784File not Downloaded 231 of 3784\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>File not Downloaded 232 of 3784\n",
      "\n",
      "\n",
      "File not Downloaded 234 of 3784File not Downloaded 233 of 3784\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "File not Downloaded 236 of 3784\n",
      "File not Downloaded 235 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 237 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 238 of 3784<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "File not Downloaded 239 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>File not Downloaded 240 of 3784\n",
      "\n",
      "File not Downloaded 241 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 242 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "File not Downloaded 243 of 3784\n",
      "File not Downloaded 244 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 245 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "File not Downloaded 246 of 3784\n",
      "File not Downloaded 247 of 3784File not Downloaded 248 of 3784\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 249 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>list index out of range\n",
      "\n",
      "\n",
      "File not Downloaded 250 of 3784\n",
      "File not Downloaded 251 of 3784File not Downloaded 252 of 3784File not Downloaded 214 of 3784\n",
      "\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>File not Downloaded 254 of 3784\n",
      "\n",
      "\n",
      "\n",
      "File not Downloaded 255 of 3784File not Downloaded 253 of 3784File not Downloaded 256 of 3784\n",
      "\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 257 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 260 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 261 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 262 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 258 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 263 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 259 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 264 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 265 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 266 of 3784\n",
      "duplicated\n",
      "Downloaded file 268 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 267 of 3784\n",
      "duplicated\n",
      "Downloaded file 269 of 3784\n",
      "duplicated\n",
      "Downloaded file 270 of 3784\n",
      "duplicated\n",
      "Downloaded file 272 of 3784\n",
      "duplicated\n",
      "Downloaded file 271 of 3784\n",
      "duplicated\n",
      "Downloaded file 273 of 3784\n",
      "Downloaded file 274 of 3784\n",
      "Downloaded file 276 of 3784\n",
      "duplicated\n",
      "Downloaded file 275 of 3784\n",
      "duplicated\n",
      "Downloaded file 277 of 3784\n",
      "Downloaded file 278 of 3784\n",
      "Downloaded file 282 of 3784\n",
      "duplicated\n",
      "Downloaded file 283 of 3784\n",
      "duplicated\n",
      "Downloaded file 279 of 3784\n",
      "Downloaded file 280 of 3784\n",
      "duplicated\n",
      "Downloaded file 281 of 3784\n",
      "Downloaded file 284 of 3784\n",
      "duplicated\n",
      "Downloaded file 285 of 3784\n",
      "Downloaded file 288 of 3784\n",
      "Downloaded file 286 of 3784\n",
      "duplicated\n",
      "Downloaded file 287 of 3784\n",
      "duplicated\n",
      "Downloaded file 289 of 3784\n",
      "Downloaded file 290 of 3784\n",
      "duplicated\n",
      "Downloaded file 291 of 3784\n",
      "Downloaded file 292 of 3784\n",
      "duplicated\n",
      "Downloaded file 293 of 3784\n",
      "Downloaded file 294 of 3784\n",
      "Downloaded file 296 of 3784\n",
      "duplicated\n",
      "Downloaded file 295 of 3784\n",
      "duplicated\n",
      "Downloaded file 297 of 3784\n",
      "Downloaded file 298 of 3784\n",
      "HTTP Error 301: The HTTP server returned a redirect error that would lead to an infinite loop.\n",
      "The last 30x error message was:\n",
      "Moved Permanently\n",
      "File not Downloaded 300 of 3784\n",
      "duplicated\n",
      "Downloaded file 299 of 3784\n",
      "HTTP Error 301: The HTTP server returned a redirect error that would lead to an infinite loop.\n",
      "The last 30x error message was:\n",
      "Moved Permanently\n",
      "File not Downloaded 301 of 3784\n",
      "HTTP Error 301: The HTTP server returned a redirect error that would lead to an infinite loop.\n",
      "The last 30x error message was:\n",
      "Moved Permanently\n",
      "File not Downloaded 302 of 3784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file 306 of 3784\n",
      "HTTP Error 301: The HTTP server returned a redirect error that would lead to an infinite loop.\n",
      "The last 30x error message was:\n",
      "Moved Permanently\n",
      "File not Downloaded 303 of 3784\n",
      "duplicated\n",
      "Downloaded file 307 of 3784\n",
      "HTTP Error 301: The HTTP server returned a redirect error that would lead to an infinite loop.\n",
      "The last 30x error message was:\n",
      "Moved Permanently\n",
      "File not Downloaded 304 of 3784\n",
      "HTTP Error 301: The HTTP server returned a redirect error that would lead to an infinite loop.\n",
      "The last 30x error message was:\n",
      "Moved Permanently\n",
      "File not Downloaded 305 of 3784\n",
      "Downloaded file 308 of 3784\n",
      "Downloaded file 310 of 3784\n",
      "duplicated\n",
      "Downloaded file 309 of 3784\n",
      "duplicated\n",
      "Downloaded file 311 of 3784\n",
      "Downloaded file 313 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 316 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 317 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 318 of 3784\n",
      "duplicated\n",
      "Downloaded file 312 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 319 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 320 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 321 of 3784\n",
      "Downloaded file 314 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 322 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 323 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 324 of 3784\n",
      "duplicated\n",
      "Downloaded file 315 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 325 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 326 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 329 of 3784\n",
      "duplicated\n",
      "Downloaded file 330 of 3784\n",
      "duplicated\n",
      "Downloaded file 331 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 333 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 334 of 3784\n",
      "duplicated\n",
      "Downloaded file 332 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 335 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 336 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 337 of 3784\n",
      "list index out of rangelist index out of range\n",
      "\n",
      "File not Downloaded 327 of 3784File not Downloaded 328 of 3784\n",
      "\n",
      "list index out of range\n",
      "File not Downloaded 338 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 339 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 343 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 344 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 345 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 346 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 347 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 348 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 349 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 350 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 351 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 352 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 353 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 354 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 355 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 356 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 357 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 358 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 359 of 3784list index out of range\n",
      "\n",
      "File not Downloaded 341 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 360 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 361 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "File not Downloaded 362 of 3784File not Downloaded 363 of 3784\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>File not Downloaded 364 of 3784\n",
      "\n",
      "File not Downloaded 365 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>File not Downloaded 366 of 3784\n",
      "\n",
      "File not Downloaded 367 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 369 of 3784File not Downloaded 368 of 3784\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "File not Downloaded 371 of 3784File not Downloaded 370 of 3784\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 373 of 3784\n",
      "File not Downloaded 372 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 374 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 375 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 376 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "File not Downloaded 377 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>list index out of range\n",
      "\n",
      "File not Downloaded 379 of 3784\n",
      "File not Downloaded 378 of 3784\n",
      "File not Downloaded 342 of 3784\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "File not Downloaded 382 of 3784File not Downloaded 381 of 3784File not Downloaded 380 of 3784\n",
      "\n",
      "\n",
      "list index out of range\n",
      "<urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known><urlopen error [Errno -2] Name or service not known>File not Downloaded 340 of 3784\n",
      "\n",
      "\n",
      "\n",
      "File not Downloaded 383 of 3784File not Downloaded 385 of 3784File not Downloaded 384 of 3784\n",
      "\n",
      "\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "<urlopen error [Errno -2] Name or service not known>File not Downloaded 388 of 3784\n",
      "File not Downloaded 389 of 3784\n",
      "\n",
      "list index out of range\n",
      "File not Downloaded 390 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 387 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 386 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 391 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 392 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 393 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 394 of 3784\n",
      "duplicated\n",
      "Downloaded file 396 of 3784\n",
      "list index out of range\n",
      "File not Downloaded 395 of 3784\n",
      "duplicated\n",
      "Downloaded file 397 of 3784\n",
      "duplicated\n",
      "Downloaded file 398 of 3784\n",
      "duplicated\n",
      "Downloaded file 399 of 3784\n",
      "duplicated\n",
      "Downloaded file 400 of 3784\n",
      "duplicated\n",
      "Downloaded file 401 of 3784\n",
      "Downloaded file 404 of 3784\n",
      "Downloaded file 402 of 3784\n",
      "duplicated\n",
      "Downloaded file 405 of 3784\n",
      "Downloaded file 406 of 3784\n",
      "duplicated\n",
      "Downloaded file 403 of 3784\n",
      "duplicated\n",
      "Downloaded file 407 of 3784\n",
      "Downloaded file 410 of 3784\n",
      "duplicated\n",
      "Downloaded file 411 of 3784\n",
      "Downloaded file 408 of 3784\n",
      "duplicated\n",
      "Downloaded file 409 of 3784\n",
      "Downloaded file 412 of 3784\n",
      "Downloaded file 415 of 3784\n",
      "duplicated\n",
      "Downloaded file 413 of 3784\n",
      "duplicated\n",
      "Downloaded file 414 of 3784\n",
      "Downloaded file 416 of 3784\n",
      "duplicated\n",
      "Downloaded file 417 of 3784\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "import csv\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import urllib.request\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "# pprint library is used to make the output look more pretty\n",
    "from pprint import pprint\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db=client.articles\n",
    "# Issue the serverStatus command and print the results\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "articleUrls = [] #stores article urls\n",
    "articleUrlsToCrawl = [] #stores article urls\n",
    "articles = [] #stores articles\n",
    "sources = [] #stores site patterns and other infos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "def readUrls():\n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(list(db.urls.find({\"stored\":0})))\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "# In[536]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "def saveItemCSV(obj):\n",
    "    try:\n",
    "        db.items.insert(obj)\n",
    "        db.urls.update({ \"articleUrl\": obj[\"url\"] },{'$set': {\"stored\":1}},upsert=False)\n",
    "    except Exception as exc:\n",
    "        \n",
    "        print(\"duplicated\")\n",
    "\n",
    "     \n",
    "        \n",
    "        \n",
    " \n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "def crawlPageTypeOpinions():\n",
    "\n",
    "   \n",
    "    # We can use a with statement to ensure threads are cleaned up promptly\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        # Start the load operations and mark each future with its URL\n",
    "        future_to_url = {executor.submit(crawlPageTypeOpinion, url, 60): url for url in range(0, len(articleUrlsToCrawl)-1)}\n",
    "        for future in concurrent.futures.as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "            except Exception as exc:\n",
    "                print(\"error\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def crawlPageTypeOpinion(i, timeout):\n",
    "    import re\n",
    "    items = []\n",
    "    \n",
    "    #for i in range(articleUrlsToCrawl.index.values[0], max):      \n",
    "        \n",
    "        \n",
    "        \n",
    "    try:\n",
    "        path = articleUrlsToCrawl.loc[i][\"articleUrl\"];\n",
    "\n",
    "        r = urllib.request.urlopen(path,timeout=timeout).read()\n",
    "\n",
    "      \n",
    "        soup = BeautifulSoup(r,\"lxml\")\n",
    "            \n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            #print datetime\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "           \n",
    "            \n",
    "            \n",
    "\n",
    "        exec('datetime = ' +sources.loc[sources[\"rootUrl\"] == articleUrlsToCrawl.loc[0][\"rootUrl\"]][\"datePattern\"][0],locals())\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "          \n",
    "            \n",
    "            \n",
    "            \n",
    "        exec('title = '+sources.loc[sources[\"rootUrl\"] == articleUrlsToCrawl.loc[0][\"rootUrl\"]][\"titlePattern\"][0],locals())\n",
    "            \n",
    "            #print title\n",
    "\n",
    "        \n",
    "\n",
    "            #print body\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "        exec('body = ' +sources.loc[sources[\"rootUrl\"] == articleUrlsToCrawl.loc[0][\"rootUrl\"]][\"bodyPattern\"][0],locals())\n",
    "            \n",
    "            \n",
    "           \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            #print '.'.join(text)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "            \n",
    "            #print author\n",
    "\n",
    "\n",
    "           \n",
    "           \n",
    "           \n",
    "            \n",
    "            \n",
    "\n",
    "        exec('author = ' +sources.loc[sources[\"rootUrl\"] == articleUrlsToCrawl.loc[0][\"rootUrl\"]][\"authorPattern\"][0],locals())\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "       \n",
    "            \n",
    "        saveItemCSV({\"source\" : sources.loc[sources[\"rootUrl\"] == articleUrlsToCrawl.loc[0][\"rootUrl\"]][\"rootUrl\"][0], \"title\" : re.sub('[^a-zA-Z ]', '', locals()['title']), \"body\" : re.sub('[^a-zA-Z ]', '', locals()['body']), \"author\" : locals()['author'], \"datetime\" : locals()['datetime'], \"url\" : path, \"category\":sources.loc[sources[\"rootUrl\"] == articleUrlsToCrawl.loc[0][\"rootUrl\"]][\"category\"][0], \"analysed\":0 })\n",
    "          \n",
    "       \n",
    "     \n",
    "          \n",
    "            \n",
    "        print (\"Downloaded file \"+str(i+1)+\" of \"+str(len(articleUrlsToCrawl)))\n",
    "            \n",
    "    except Exception as e: \n",
    "            \n",
    "        print(e)\n",
    "    \n",
    "        db.urls.update({ \"articleUrl\": path },{'$set': {\"stored\":\"Not Accessible\"}},upsert=False)\n",
    "        print (\"File not Downloaded \"+str(i+1)+\" of \"+str(len(articleUrlsToCrawl)))\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    return items\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "latestArticle = \"\"\n",
    "updatedCount = 0\n",
    "\n",
    "def saveUrl(obj):\n",
    "    \n",
    "    \n",
    "    \n",
    "     db.urls.update({\"noExist\": True}, {\"$setOnInsert\": obj}, upsert = True)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "def readSites():\n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(list(db.sites.find()))\n",
    "\n",
    "\n",
    "def readLastArticle(rootUrl):\n",
    "    \n",
    "    \n",
    "    if len(list(db.urls.find({\"rootUrl\":rootUrl}).limit(1))) == 0:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return list(db.urls.find({\"rootUrl\":rootUrl}).limit(1))[0][\"articleUrl\"]\n",
    "\n",
    "\n",
    "\n",
    "def getArticlesUrl(file, source, rootUrl):\n",
    "    import re\n",
    "\n",
    "    global updatedCount\n",
    "    global latestArticle\n",
    "    \n",
    "    status = True\n",
    "   \n",
    "    \n",
    "    soup = BeautifulSoup(file, \"lxml\")\n",
    "        \n",
    "  \n",
    "    exec('items = '+source[\"urlPattern\"],locals())\n",
    "     \n",
    "    \n",
    "    \n",
    "    for item in locals()[\"items\"]:\n",
    "        \n",
    "        try:\n",
    "            if item[\"href\"].find(source[\"rootUrl\"])==-1:\n",
    "                if latestArticle != source[\"rootUrl\"]+item[\"href\"]:\n",
    "                    saveUrl({\"articleUrl\":source[\"rootUrl\"]+item[\"href\"], \"rootUrl\":source[\"rootUrl\"], \"rootUrl\":rootUrl,\"stored\":0})\n",
    "                    updatedCount = updatedCount+1\n",
    "                else:\n",
    "                    status = False\n",
    "                    break\n",
    "            else:\n",
    "\n",
    "                if latestArticle != item[\"href\"]:\n",
    "                    saveUrl({\"articleUrl\":item[\"href\"], \"rootUrl\":source[\"rootUrl\"], \"rootUrl\":rootUrl, \"stored\":0})\n",
    "                    updatedCount = updatedCount+1\n",
    "                else:\n",
    "                    status = False\n",
    "                    break\n",
    "        except Exception as e: \n",
    "            \n",
    "            print(e)\n",
    "\n",
    "    return status\n",
    "\n",
    "def crawlPageTypeOpinionsUrlList(source):   \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0, 1000000000):      \n",
    "\n",
    "        try:\n",
    "            path = source[\"url\"]+str(i)\n",
    "            \n",
    "            \n",
    "\n",
    "            r = urllib.request.urlopen(path).read()\n",
    "\n",
    "            status = getArticlesUrl(r, source, source[\"rootUrl\"])    \n",
    "            \n",
    "            if status == False:\n",
    "                break\n",
    "                \n",
    "                \n",
    "            print (\"Downloaded file: \"+str(i) + \" of \"+str(source[\"size\"]))\n",
    "\n",
    "        except Exception as e: \n",
    "            \n",
    "            print(e)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#load sources from site.csv\n",
    "sources = readSites()\n",
    "\n",
    "\n",
    "\n",
    "# In[537]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(sources)):\n",
    "    \n",
    "    \n",
    "    print(\"Downloaded Articles\\n\")\n",
    "    updatedCount = 0\n",
    "    \n",
    "    latestArticle = readLastArticle(sources.loc[i][\"rootUrl\"])\n",
    "    crawlPageTypeOpinionsUrlList(sources.loc[i])\n",
    "    print(sources.loc[i][\"rootUrl\"]+\": \"+str(updatedCount))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "articleUrlsToCrawl =  readUrls()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "crawlPageTypeOpinions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "import csv\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import urllib.request\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "# pprint library is used to make the output look more pretty\n",
    "from pprint import pprint\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db=client.articles\n",
    "# Issue the serverStatus command and print the results\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "articleUrls = [] #stores article urls\n",
    "articleUrlsToCrawl = [] #stores article urls\n",
    "articles = [] #stores articles\n",
    "sources = [] #stores site patterns and other infos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "def readUrls():\n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(list(db.urls.find({\"stored\":0})))\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "# In[536]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "def saveItemCSV(obj):\n",
    "    try:\n",
    "        db.items.insert(obj)\n",
    "        db.urls.update_many({ \"articleUrl\": obj[\"url\"] },{'$set': {\"stored\":1}},upsert=False)\n",
    "    except Exception as exc:\n",
    "\t\n",
    "        \n",
    "        print(\"duplicated\")\n",
    "\n",
    "     \n",
    "        \n",
    "        \n",
    " \n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "def crawlPageTypeOpinions():\n",
    "\n",
    "   \n",
    "    # We can use a with statement to ensure threads are cleaned up promptly\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        # Start the load operations and mark each future with its URL\n",
    "        future_to_url = {executor.submit(crawlPageTypeOpinion, url, 60): url for url in range(0, len(articleUrlsToCrawl)-1)}\n",
    "        for future in concurrent.futures.as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "            except Exception as exc:\n",
    "                print(\"error\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def crawlPageTypeOpinion(i, timeout):\n",
    "    import re\n",
    "    items = []\n",
    "    \n",
    "    #for i in range(articleUrlsToCrawl.index.values[0], max):      \n",
    "        \n",
    "        \n",
    "        \n",
    "    try:\n",
    "        path = articleUrlsToCrawl.loc[i][\"articleUrl\"];\n",
    "\n",
    "        r = urllib.request.urlopen(path,timeout=timeout).read()\n",
    "\n",
    "      \n",
    "        soup = BeautifulSoup(r,\"lxml\")\n",
    "            \n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            #print datetime\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "           \n",
    "            \n",
    "            \n",
    "\n",
    "        exec('datetime = ' +sources.loc[sources[\"rootUrl\"] == articleUrlsToCrawl.loc[0][\"rootUrl\"]][\"datePattern\"][0],locals())\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "          \n",
    "            \n",
    "            \n",
    "            \n",
    "        exec('title = '+sources.loc[sources[\"rootUrl\"] == articleUrlsToCrawl.loc[0][\"rootUrl\"]][\"titlePattern\"][0],locals())\n",
    "            \n",
    "            #print title\n",
    "\n",
    "        \n",
    "\n",
    "            #print body\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "        exec('body = ' +sources.loc[sources[\"rootUrl\"] == articleUrlsToCrawl.loc[0][\"rootUrl\"]][\"bodyPattern\"][0],locals())\n",
    "            \n",
    "            \n",
    "           \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            #print '.'.join(text)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "            \n",
    "            #print author\n",
    "\n",
    "\n",
    "           \n",
    "           \n",
    "           \n",
    "            \n",
    "            \n",
    "\n",
    "        exec('author = ' +sources.loc[sources[\"rootUrl\"] == articleUrlsToCrawl.loc[0][\"rootUrl\"]][\"authorPattern\"][0],locals())\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "       \n",
    "            \n",
    "        saveItemCSV({\"source\" : sources.loc[sources[\"rootUrl\"] == articleUrlsToCrawl.loc[0][\"rootUrl\"]][\"rootUrl\"][0], \"title\" : re.sub('[^a-zA-Z ]', '', locals()['title']), \"body\" : BeautifulSoup(locals()['body'],\"lxml\").text.replace(\"\\n\",\"\"), \"author\" : locals()['author'], \"datetime\" : locals()['datetime'], \"url\" : path, \"category\":sources.loc[sources[\"rootUrl\"] == articleUrlsToCrawl.loc[0][\"rootUrl\"]][\"category\"][0], \"analysed\":0 })\n",
    "          \n",
    "       \n",
    "     \n",
    "          \n",
    "            \n",
    "        print (\"Downloaded file \"+str(i+1)+\" of \"+str(len(articleUrlsToCrawl)))\n",
    "            \n",
    "    except Exception as e: \n",
    "            \n",
    "        print(path)\n",
    "    \n",
    "\t\n",
    "        print(db.urls.update_many({ \"articleUrl\": path },{'$set': {\"stored\":\"Not Accessible\"}},upsert=False))\n",
    "        print (\"File not Downloaded \"+str(i+1)+\" of \"+str(len(articleUrlsToCrawl)))\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    return items\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "latestArticle = \"\"\n",
    "updatedCount = 0\n",
    "\n",
    "def saveUrl(obj):\n",
    "    \n",
    "    \n",
    "    \n",
    "     db.urls.update_many({\"noExist\": True}, {\"$setOnInsert\": obj}, upsert = True)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "def readSites():\n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(list(db.sites.find()))\n",
    "\n",
    "\n",
    "def readLastArticle(rootUrl):\n",
    "    \n",
    "    obj = len(list(db.urls.find({\"articleUrl\":rootUrl}).limit(1)))\n",
    "    \n",
    "\n",
    "    if len(obj) == 0:\n",
    "        return True\n",
    "    elif obj[0][\"stored\"]==\"Not Accessible\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def getArticlesUrl(file, source, rootUrl):\n",
    "    import re\n",
    "\n",
    "    global updatedCount\n",
    "    global latestArticle\n",
    "    \n",
    "    status = True\n",
    "   \n",
    "    \n",
    "    soup = BeautifulSoup(file, \"lxml\")\n",
    "        \n",
    "  \n",
    "    exec('items = '+source[\"urlPattern\"],locals())\n",
    "     \n",
    "    \n",
    "    \n",
    "    for item in locals()[\"items\"]:\n",
    "        \n",
    "        try:\n",
    "            if item[\"href\"].find(source[\"rootUrl\"])==-1:\n",
    "                if readLastArticle(source[\"rootUrl\"]+item[\"href\"]):\n",
    "                    saveUrl({\"articleUrl\":source[\"rootUrl\"]+item[\"href\"], \"rootUrl\":source[\"rootUrl\"], \"rootUrl\":rootUrl,\"stored\":0})\n",
    "                    updatedCount = updatedCount+1\n",
    "                else:\n",
    "                    status = False\n",
    "                    break\n",
    "            else:\n",
    "\n",
    "                if readLastArticle(item[\"href\"]):\n",
    "                    saveUrl({\"articleUrl\":item[\"href\"], \"rootUrl\":source[\"rootUrl\"], \"rootUrl\":rootUrl, \"stored\":0})\n",
    "                    updatedCount = updatedCount+1\n",
    "                else:\n",
    "                    status = False\n",
    "                    break\n",
    "        except Exception as e: \n",
    "            \n",
    "            print(e)\n",
    "\n",
    "    return status\n",
    "\n",
    "def crawlPageTypeOpinionsUrlList(source):   \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0, 1000000000):      \n",
    "\n",
    "        try:\n",
    "            path = source[\"url\"]+str(i)\n",
    "            \n",
    "            \n",
    "\n",
    "            r = urllib.request.urlopen(path).read()\n",
    "\n",
    "            status = getArticlesUrl(r, source, source[\"rootUrl\"])    \n",
    "            \n",
    "            if status == False:\n",
    "                break\n",
    "                \n",
    "                \n",
    "            print (\"Downloaded file: \"+str(i) + \" of \"+str(source[\"size\"]))\n",
    "\n",
    "        except Exception as e: \n",
    "            \n",
    "            print(e)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#load sources from site.csv\n",
    "sources = readSites()\n",
    "\n",
    "\n",
    "\n",
    "# In[537]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(sources)):\n",
    "    \n",
    "    \n",
    "    print(\"Downloaded Articles\\n\")\n",
    "    updatedCount = 0\n",
    "    \n",
    "    \n",
    "    crawlPageTypeOpinionsUrlList(sources.loc[i])\n",
    "    print(sources.loc[i][\"rootUrl\"]+\": \"+str(updatedCount))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "articleUrlsToCrawl =  readUrls()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "crawlPageTypeOpinions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
